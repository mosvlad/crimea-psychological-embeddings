# Crimean Student Psychology Survey Analysis

Проект для автоматизированного анализа текстовых ответов из психологических опросов школьников Крыма, используя современные методы обработки естественного языка (NLP) и кластеризации.

![Обзор проекта](https://github.com/user-attachments/assets/fd91660e-d47c-46a9-abfd-4077616ba142)

*Пример визуализации результатов кластеризации ответов школьников*

## Описание проекта

Данный проект предназначен для анализа текстовых ответов из психологических опросов, проведенных среди школьников различных районов и городских округов Республики Крым. Используя методы машинного обучения и NLP, проект позволяет выявлять схожие паттерны в ответах, кластеризовать их и визуализировать выявленные закономерности.

### Ключевые возможности

- Предобработка текстовых данных опросов
- Создание многоязычных эмбеддингов текста с использованием Sentence-Transformers
- Кластеризация ответов с помощью алгоритма HDBSCAN
- Анализ данных по регионам Крыма
- Визуализация кластеров с помощью t-SNE и Plotly
- Поиск семантически похожих ответов
- Тематическое моделирование текстов с BERTopic (бета)
- Оптимизация производительности с использованием кэширования

## Установка

```bash
# Клонирование репозитория
git clone https://github.com/mosvlad/crimea-psychological-embeddings
cd crimea-psychological-embeddings

# Создание виртуального окружения
python -m venv venv
source venv/bin/activate  # Linux/Mac
# или
venv\Scripts\activate  # Windows

# Установка зависимостей
pip install -r requirements.txt
```

### Зависимости

Проект использует следующие библиотеки:
- pandas
- numpy
- scikit-learn
- sentence-transformers
- hdbscan
- plotly
- bertopic (для расширенного анализа)

Полный список зависимостей находится в файле `requirements.txt`.

## Структура проекта

```
crimean-survey-nlp-clustering/
├── data/                     # Директория с исходными данными
│   ├── data_1-4.csv          # Данные 1-4 классов
│   └── data_8-11.csv         # Данные 8-11 классов
├── cache/                    # Кэшированные эмбеддинги (создается автоматически)
├── results/                  # Результаты анализа (создается автоматически)
├── main.py                   # Основной скрипт
├── main_by_region.py         # Cкрипт обработки данных по регионам
├── requirements.txt          # Зависимости проекта
└── README.md                 # Документация проекта
```


![Структура директории](https://github.com/user-attachments/assets/e37baaf5-5fbe-4657-9e42-d069c6aa8f4c)

*Пример организации файлов в директории results/ после выполнения анализа.*

## Использование

### Базовый анализ

```bash
python main.py
```

Этот скрипт загружает данные из файла и анализирует их вне зависимости от региона. Результаты сохраняются в директории `results/`.

### Анализ по регионам

```bash
python main_by_region.py
```

Этот скрипт загружает данные из файла и анализирует их отдельно для каждого региона Крыма. Результаты сохраняются в директории `results/`.

## Методология

Проект использует следующую методологию:

1. **Предобработка текста**: нормализация, удаление пунктуации и приведение к нижнему регистру.
2. **Создание эмбеддингов**: многоязычная модель Sentence-Transformers для векторизации текстовых ответов.
3. **Кластеризация**: алгоритм HDBSCAN для обнаружения кластеров в пространстве эмбеддингов.
4. **Визуализация**: метод t-SNE для снижения размерности и Plotly для интерактивной визуализации.
5. **Поиск похожих ответов**: матрица косинусного сходства для обнаружения семантически близких ответов.
6. **Тематическое моделирование**: метод BERTopic для выявления основных тем в ответах. (бета)

## Результаты

После выполнения скриптов в директории `results/` создаются:

- `*_cluster_info_*.json` - информация о кластерах, включая размеры и примеры ответов
- `*_clusters_*.html` - интерактивные визуализации кластеров
- `similar_answers.json` - группы похожих ответов (бета)
- `topics_*.json` - информация о выявленных темах (при использовании BERTopic) (бета)

### Визуализация результатов

#### Кластеризация ответов (t-SNE)

![Кластер "человека паука"](https://github.com/user-attachments/assets/c1c8cf63-1120-45cc-88dd-b71982793c3d)

*Визуализация кластеров ответов на вопрос "Представь_что_тебя_попросили_создать_интернет_страницу_от_лица_героя_или_персонажа"

#### Информация о кластерах

![Информация о кластерах](https://github.com/user-attachments/assets/60692259-c398-4a83-b906-882aaaa9bef4)

*Пример структурированной информации о выявленных кластерах, включая размер, процентное соотношение и примеры ответов.*

## Настройка

Основные параметры можно настроить в начале скриптов:

- Путь к файлам данных
- Модель для создания эмбеддингов
- Параметры алгоритма HDBSCAN
- Порог сходства для определения похожих ответов

### Пример настройки параметров

```python
# Настройка модели эмбеддингов
embedder = TextEmbedder(model_name='sentence-transformers/paraphrase-multilingual-mpnet-base-v2')

# Настройка параметров кластеризации HDBSCAN
clusterer = hdbscan.HDBSCAN(
    min_cluster_size=5,  # Минимальный размер кластера
    min_samples=3,       # Минимальное количество близких точек
    metric='euclidean',  # Метрика расстояния
    cluster_selection_method='eom',  # Метод выбора кластеров
    core_dist_n_jobs=-1  # Использовать все ядра CPU
)
```

## Лицензия

[MIT License](https://opensource.org/licenses/MIT)

---

*Примечание*: Для работы с большими наборами данных рекомендуется использовать компьютер с достаточным объемом оперативной памяти.
